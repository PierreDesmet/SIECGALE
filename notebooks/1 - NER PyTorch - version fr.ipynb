{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee1bbd61",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "# 1 - NER PyTorch - version française\n",
    "\n",
    "\n",
    "**TODO**\n",
    "- [x] changer le padding par une autre valeur -> pas besoin en définitive.\n",
    "- [x] set num workers (minitrain, valid et test)\n",
    "- [x] peut-on monter la taille des batchs ? \n",
    "- [x] stratifier les splits\n",
    "- [x] enregistrer la running loss\n",
    "- [x] changer la self.padding_value, elle est fausse pour CamemBERT\n",
    "- [ ] vérifier que ce notebook marche encore pour la langue anglaise, supprimer le NB 1 et commit\n",
    "- [ ] est-on sûr que les special tokens ne contribuent pas à la loss ?\n",
    "\n",
    "Optimisations : \n",
    "- [ ] gradual unfreezing\n",
    "- [ ] early stopping avec lightning\n",
    "- [ ] POS des mots autour\n",
    "- [ ] wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a81c077",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T20:58:46.619737Z",
     "start_time": "2022-07-26T20:58:44.855487Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import joblib\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "os.chdir('..')\n",
    "\n",
    "from ner_pytorch.config.params import PARAMS\n",
    "from ner_pytorch.dataset import EntityDataset\n",
    "from ner_pytorch.engine import eval_fn, train_fn, prédit_single_doc\n",
    "from ner_pytorch.model import EntityModel\n",
    "from ner_pytorch.preprocessing import process_data\n",
    "from ner_pytorch.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d9082c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ad7a2df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T20:58:47.040149Z",
     "start_time": "2022-07-26T20:58:46.621888Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "      <th>source</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phrase 1</td>\n",
       "      <td>On</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Phrase 1</td>\n",
       "      <td>la</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Phrase 1</td>\n",
       "      <td>trouve</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Phrase 1</td>\n",
       "      <td>depuis</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Phrase 1</td>\n",
       "      <td>le</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Phrase 1</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Phrase 1</td>\n",
       "      <td>jusqu'</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentence #      Word Tag      source                     ID\n",
       "0   Phrase 1        On   O  Wikineural  Wikineural - Phrase 1\n",
       "1   Phrase 1        la   O  Wikineural  Wikineural - Phrase 1\n",
       "2   Phrase 1    trouve   O  Wikineural  Wikineural - Phrase 1\n",
       "3   Phrase 1    depuis   O  Wikineural  Wikineural - Phrase 1\n",
       "4   Phrase 1        le   O  Wikineural  Wikineural - Phrase 1\n",
       "5   Phrase 1  Pakistan   O  Wikineural  Wikineural - Phrase 1\n",
       "6   Phrase 1    jusqu'   O  Wikineural  Wikineural - Phrase 1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if PARAMS.LANGUAGE == 'fr':\n",
    "    data = pd.read_feather(PARAMS.PATHS_FR.TRAIN)\n",
    "    data = data.rename(columns={'Phrase': 'Sentence #', 'Mot': 'Word', 'Label': 'Tag'})\n",
    "elif PARAMS.LANGUAGE == 'en':\n",
    "    data = pd.read_csv(PARAMS.PATHS_EN.TRAIN, encoding='latin-1').drop('POS', axis=1)\n",
    "    data[\"Sentence #\"] = data[\"Sentence #\"].fillna(method='ffill')\n",
    "    data['ID'] = data['Sentence #']\n",
    "data.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1a3d27",
   "metadata": {
    "hidden": true
   },
   "source": [
    "En réalité, nous ne nous intéressons qu'à la prédiction des ORG, pour lesquelles 3 labels sont possibles :\n",
    "- B-org\n",
    "- I-org\n",
    "- O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2009ee77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T20:58:47.227041Z",
     "start_time": "2022-07-26T20:58:47.041631Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O        0.963958\n",
       "B-org    0.021774\n",
       "I-org    0.014268\n",
       "Name: Tag, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Tag'] = data.Tag.mask(~data.Tag.isin(['B-org', 'I-org', 'O']), 'O')\n",
    "data.Tag.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bbb03a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T20:58:47.389762Z",
     "start_time": "2022-07-26T20:58:47.229286Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag 3 categories : ['O' 'B-org' 'I-org']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1305469, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "      <th>source</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>265234</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>\"</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265235</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265236</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>connu</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265237</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>au</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265238</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>Japon</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265239</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>sous</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265240</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>le</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265241</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>nom</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265242</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265243</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>ou</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265244</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>bien</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265245</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>\"</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265246</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>en</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265247</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>Amérique</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265248</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>du</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265249</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>Nord</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265250</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265251</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>est</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265252</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>un</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265253</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>jeu</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265254</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>vidéo</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265255</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>d'</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265256</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>action</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265257</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>-</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265258</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>plates-formes</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265259</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>développé</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265260</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>et</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265261</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>édité</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265262</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>par</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265263</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>Natsume</td>\n",
       "      <td>B-org</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265264</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>en</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265265</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>1990</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265266</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>sur</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265267</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>la</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265268</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>console</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265269</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>B-org</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265270</th>\n",
       "      <td>Phrase 11022</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>Wikineural</td>\n",
       "      <td>Wikineural - Phrase 11022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Sentence #           Word    Tag      source  \\\n",
       "265234  Phrase 11022              \"      O  Wikineural   \n",
       "265235  Phrase 11022              ,      O  Wikineural   \n",
       "265236  Phrase 11022          connu      O  Wikineural   \n",
       "265237  Phrase 11022             au      O  Wikineural   \n",
       "265238  Phrase 11022          Japon      O  Wikineural   \n",
       "265239  Phrase 11022           sous      O  Wikineural   \n",
       "265240  Phrase 11022             le      O  Wikineural   \n",
       "265241  Phrase 11022            nom      O  Wikineural   \n",
       "265242  Phrase 11022              ,      O  Wikineural   \n",
       "265243  Phrase 11022             ou      O  Wikineural   \n",
       "265244  Phrase 11022           bien      O  Wikineural   \n",
       "265245  Phrase 11022              \"      O  Wikineural   \n",
       "265246  Phrase 11022             en      O  Wikineural   \n",
       "265247  Phrase 11022       Amérique      O  Wikineural   \n",
       "265248  Phrase 11022             du      O  Wikineural   \n",
       "265249  Phrase 11022           Nord      O  Wikineural   \n",
       "265250  Phrase 11022              ,      O  Wikineural   \n",
       "265251  Phrase 11022            est      O  Wikineural   \n",
       "265252  Phrase 11022             un      O  Wikineural   \n",
       "265253  Phrase 11022            jeu      O  Wikineural   \n",
       "265254  Phrase 11022          vidéo      O  Wikineural   \n",
       "265255  Phrase 11022             d'      O  Wikineural   \n",
       "265256  Phrase 11022         action      O  Wikineural   \n",
       "265257  Phrase 11022              -      O  Wikineural   \n",
       "265258  Phrase 11022  plates-formes      O  Wikineural   \n",
       "265259  Phrase 11022      développé      O  Wikineural   \n",
       "265260  Phrase 11022             et      O  Wikineural   \n",
       "265261  Phrase 11022          édité      O  Wikineural   \n",
       "265262  Phrase 11022            par      O  Wikineural   \n",
       "265263  Phrase 11022        Natsume  B-org  Wikineural   \n",
       "265264  Phrase 11022             en      O  Wikineural   \n",
       "265265  Phrase 11022           1990      O  Wikineural   \n",
       "265266  Phrase 11022            sur      O  Wikineural   \n",
       "265267  Phrase 11022             la      O  Wikineural   \n",
       "265268  Phrase 11022        console      O  Wikineural   \n",
       "265269  Phrase 11022       Nintendo  B-org  Wikineural   \n",
       "265270  Phrase 11022              .      O  Wikineural   \n",
       "\n",
       "                               ID  \n",
       "265234  Wikineural - Phrase 11022  \n",
       "265235  Wikineural - Phrase 11022  \n",
       "265236  Wikineural - Phrase 11022  \n",
       "265237  Wikineural - Phrase 11022  \n",
       "265238  Wikineural - Phrase 11022  \n",
       "265239  Wikineural - Phrase 11022  \n",
       "265240  Wikineural - Phrase 11022  \n",
       "265241  Wikineural - Phrase 11022  \n",
       "265242  Wikineural - Phrase 11022  \n",
       "265243  Wikineural - Phrase 11022  \n",
       "265244  Wikineural - Phrase 11022  \n",
       "265245  Wikineural - Phrase 11022  \n",
       "265246  Wikineural - Phrase 11022  \n",
       "265247  Wikineural - Phrase 11022  \n",
       "265248  Wikineural - Phrase 11022  \n",
       "265249  Wikineural - Phrase 11022  \n",
       "265250  Wikineural - Phrase 11022  \n",
       "265251  Wikineural - Phrase 11022  \n",
       "265252  Wikineural - Phrase 11022  \n",
       "265253  Wikineural - Phrase 11022  \n",
       "265254  Wikineural - Phrase 11022  \n",
       "265255  Wikineural - Phrase 11022  \n",
       "265256  Wikineural - Phrase 11022  \n",
       "265257  Wikineural - Phrase 11022  \n",
       "265258  Wikineural - Phrase 11022  \n",
       "265259  Wikineural - Phrase 11022  \n",
       "265260  Wikineural - Phrase 11022  \n",
       "265261  Wikineural - Phrase 11022  \n",
       "265262  Wikineural - Phrase 11022  \n",
       "265263  Wikineural - Phrase 11022  \n",
       "265264  Wikineural - Phrase 11022  \n",
       "265265  Wikineural - Phrase 11022  \n",
       "265266  Wikineural - Phrase 11022  \n",
       "265267  Wikineural - Phrase 11022  \n",
       "265268  Wikineural - Phrase 11022  \n",
       "265269  Wikineural - Phrase 11022  \n",
       "265270  Wikineural - Phrase 11022  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tag = data.Tag.nunique()\n",
    "print(f'Tag {num_tag} categories :', data.Tag.unique(), end='\\n\\n')\n",
    "\n",
    "data.shape\n",
    "data.query(\"ID == 'Wikineural - Phrase 11022'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3782fc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T20:58:49.129721Z",
     "start_time": "2022-07-26T20:58:47.392192Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/outputs/ordinal_enc_NER_fr.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences, tag, ordinal_enc_NER = process_data(data)\n",
    "joblib.dump(ordinal_enc_NER, f'data/outputs/ordinal_enc_NER_{PARAMS.LANGUAGE}.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ff47089",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T20:58:49.153310Z",
     "start_time": "2022-07-26T20:58:49.131463Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Il', 'entame', 'ensuite', 'une', 'série', 'de', 'matchs', 'contre', 'Matt', 'Sydal', '.', 'La', 'communauté', 'de', 'communes', 'Castelnaudary', 'Lauragais', 'Audois', \"c'est\", ',', 'pour', 'chaque', 'commune', ',', 'une', 'offre', 'de', 'services', 'agrandie', 'à', 'proposer', 'à', 'ses', 'habitants', 'et', 'ses', 'entreprises', ',', 'une', 'visibilité', 'renforcée', 'par', 'un', 'lien', 'nouveau', 'et', 'un', 'avenir', 'plein', \"d'élan\", 'à', 'partager.Un', 'positionnement', 'stratégique', 'aux', 'portes', 'de', \"l'agglomération\", 'toulousaine', 'et', 'au', 'cœur', 'de', 'la', 'région', 'Occitanie', ',', 'un', 'projet', 'de', 'territoire', 'ambitieux', 'pour', 'une', 'intercommunalité', 'dynamique', '.']\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[array(['O', 'B-org', 'I-org'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "# Démo : \n",
    "i = 6\n",
    "print(sentences[i], end='\\n')\n",
    "print(tag[i], end='\\n')\n",
    "print(ordinal_enc_NER.categories_, end='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd8b218",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Split du jeu de données\n",
    "On split notre jeu de données de la façon suivante :\n",
    "- `test` = 20%\n",
    "- `train` = [`minitrain`, `valid`] = 80%\n",
    "- `minitrain` = 60%\n",
    "- `valid` = 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87f4756c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T20:58:49.404753Z",
     "start_time": "2022-07-26T20:58:49.154678Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.964141\n",
       "1.0    0.021723\n",
       "2.0    0.014136\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.963996\n",
       "1.0    0.021983\n",
       "2.0    0.014021\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(7708, 2569, 2569)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_test = int(PARAMS.SAMPLE_SIZES.TEST * len(sentences))\n",
    "len_valid = int(PARAMS.SAMPLE_SIZES.VALID * len(sentences))\n",
    "autre = ordinal_enc_NER.transform([['O']]).item()\n",
    "\n",
    "# En présence d'un jeu déséquilibré, il vaut mieux stratifier :\n",
    "strat_tag = [len([_ for _ in tag[i] if _ != autre]) > 0 for i in range(len(tag))]\n",
    "(\n",
    "    sentences_train, sentences_test,\n",
    "    tag_train, tag_test\n",
    ") = train_test_split(sentences, tag, random_state=PARAMS.SEED, \n",
    "                     test_size=len_test, stratify=strat_tag, shuffle=True)\n",
    "\n",
    "strat_tag_train = [len([_ for _ in tag_train[i] if _ != autre]) > 0 for i in range(len(tag_train))]\n",
    "(\n",
    "    sentences_minitrain, sentences_valid,\n",
    "    tag_minitrain, tag_valid\n",
    ") = train_test_split(sentences_train, tag_train, random_state=PARAMS.SEED, \n",
    "                     test_size=len_valid, stratify=strat_tag_train, shuffle=True)\n",
    "\n",
    "# Pour se rassurer sur la bonne représentativité de chaque classe dans les échantillons stratifiés : \n",
    "pd.Series(np.concatenate(tag_train)).value_counts(normalize=True)\n",
    "pd.Series(np.concatenate(tag_valid)).value_counts(normalize=True)\n",
    "\n",
    "len(sentences_minitrain), len(sentences_valid), len(sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f4ec049",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T20:58:49.428693Z",
     "start_time": "2022-07-26T20:58:49.406161Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "minitrain_dataset = EntityDataset(\n",
    "    texts=sentences_minitrain, tags=tag_minitrain\n",
    ")\n",
    "minitrain_data_loader = DataLoader(\n",
    "    minitrain_dataset, batch_size=PARAMS.MODEL.TRAIN_BATCH_SIZE, num_workers=16 \n",
    ")\n",
    "\n",
    "valid_dataset = EntityDataset(\n",
    "    texts=sentences_valid, tags=tag_valid\n",
    ")\n",
    "valid_data_loader = DataLoader(\n",
    "    valid_dataset, batch_size=PARAMS.MODEL.VALID_BATCH_SIZE, num_workers=16\n",
    ")\n",
    "\n",
    "test_dataset = EntityDataset(\n",
    "    texts=sentences_test, tags=tag_test\n",
    ")\n",
    "test_data_loader = DataLoader(\n",
    "    test_dataset, batch_size=PARAMS.MODEL.VALID_BATCH_SIZE, num_workers=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8d7fdea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T20:58:49.468432Z",
     "start_time": "2022-07-26T20:58:49.430003Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Le', 'elle', 'est', 'dans', 'la', 'région', 'de', 'Colbitz', 'et', 'Angern', 'avant', \"d'\", 'occuper', 'Hanovre', 'le', '.', 'Oldies', 'Racing', 'vous', 'fait', 'vivre', 'une', 'expérience', 'unique', 'au', 'monde', ':', 'le', 'plaisir', 'de', 'conduire', 'un', 'cyclecar', 'à', '10', 'minutes', 'du', 'stade', 'Pierre', 'Mauroy', ',', 'Des', 'sensations', 'surprenantes', 'vous', 'attendent', 'au', 'volant', \"d'une\", 'réplique', 'de', 'voiture', 'des', 'années', '1900-1920', '!', 'Entrez', 'dans', 'le', 'tout', 'premier', 'club', 'de', 'retro', 'drivers', 'et', 'venez', 'rouler', 'sur', 'notre', 'piste', 'intérieure', 'située', 'à', 'Leers.Oldies', 'Racing', ',', 'c', '’', 'est', 'également', ':', '.', 'Une', 'ambiance', 'club', ',', 'avec', 'un', 'bar', 'chaleureux', ',', 'confortable', 'et', 'convivial', 'pour', 'profiter', 'de', 'chaque', 'instant', 'de', 'pilotage', 'autour', 'd', '’', 'un', 'verre', 'ou', 'd', '’', 'un', 'snack', ',', 'en', 'appréciant', 'la', 'vue', 'panoramique', 'sur', 'la', 'piste', '.', 'Des', 'concerts', 'acoustiques', 'réguliers', 'et', 'des', 'soirées', 'thématiques', 'sont', 'également', 'organisés', 'tout', 'au', 'long', 'de', 'l', '’', 'année', ';', '.', 'Des', 'salles', 'de', 'séminaire', 'pour', 'vos', 'évènements', 'd', '’', 'entreprise', ',', 'entièrement', 'équipées', ',', 'avec', 'vue', 'panoramique', 'sur', 'la', 'piste', '.']\n",
      "ids: tensor([    5,    54,   109,    30,    29,    13,   581,     8,  2875,  3981,\n",
      "          138,    14,  9137, 10813,   178,    18,    11,  9295,  1805,  7973,\n",
      "          346,    16,    21,     9, 21977,  2364, 17135,    39,    82,   747,\n",
      "           28,  1005,   931,    36,   164,    43,    16,   593,     8,  4013,\n",
      "           23,  3178,  1292,    15,   239,   609,    25,  2623,  1140, 13369,\n",
      "         6287,    21,     7,   363,  7404, 15118,    10,    39,  7385,    36,\n",
      "         5345,    18,    11,    70,  8773,     8,   864,    20,   318, 16400,\n",
      "         2965,  1461,    83, 25684,    29,    16,    66,   246,  1046,     8,\n",
      "        20387, 27984,    10,    14,  4636,  8167,    32,   127,  3165,  3933,\n",
      "         2126,    15,    54,  2242,     9,   585,  8163,  2364, 17135,    21,\n",
      "            7,    60,    21,    12,    30,   200,    43,    21,     9,   180,\n",
      "         2889,  1046,    21,     7,    42,    23,  1372,  6311,    21,     7,\n",
      "         2794,    14, 10954,    24,  1153,     8,   251,     6])\n",
      "mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "token_type_ids: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "target_tag: tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "i = 40\n",
    "print(test_dataset.texts[i])\n",
    "for key, value in test_dataset[i].items():\n",
    "    print(key + ':', value)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "ecf777f6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Expériences pré-entraînement\n",
    "\n",
    "Avant de lancer le modèle, quelle _loss_ serait considérée comme statisfaisante ? Calculons à l'avance les loss que donneraient :\n",
    "\n",
    "- un modèle qui prédit aléatoirement \n",
    "- un modèle qui prédit la classe modale (\"O\")\n",
    "- un modèle qui prédit de façon satisfaisante, avec une accuracy donnée*\n",
    "- un modèle oracle (prédiction parfaite)\n",
    "\n",
    "*Remarque : pour deux modèles qui produisent la même accuracy fixée, l'un peut être meilleur que l'autre ! En effet, les probas prédites peuvent être plus ou moins proches de la réalité, même si elles peuvent résulter en des prédictions binaires identiques (et donc en la même accuracy).\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "103b6eee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T20:58:49.925169Z",
     "start_time": "2022-07-26T20:58:49.469964Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss_ce = nn.CrossEntropyLoss(reduction='mean')\n",
    "y_true = torch.tensor(ordinal_enc_NER.transform(data[['Tag']]), dtype=torch.long).view(-1)\n",
    "\n",
    "y_true_ohe_parfait = torch.tensor(\n",
    "    pd.get_dummies(y_true).astype(float).replace(0, -1234).to_numpy(),\n",
    "    dtype=torch.float\n",
    ")\n",
    "\n",
    "# -3 est un nombre arbitraire qui affecte à la bonne classe une proba de 5%.\n",
    "y_true_ohe = torch.tensor(\n",
    "    pd.get_dummies(y_true).astype(float).replace(0, -3).to_numpy(),\n",
    "    dtype=torch.float\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c32a6b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T20:58:50.232613Z",
     "start_time": "2022-07-26T20:58:49.926901Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss oracle : tensor(0.)\n",
      "Loss d'un modèle satisfaisant : tensor(0.1160)\n",
      "Loss du modèle qui prédit argcount : tensor(0.1801)\n",
      "Loss d'un modèle aléatoire : tensor(2.7047)\n"
     ]
    }
   ],
   "source": [
    "#  Modèle oracle :\n",
    "y_pred = y_true_ohe_parfait.detach()\n",
    "print('Loss oracle :', loss_ce(y_pred, y_true))\n",
    "\n",
    "# Modèle avec une accuracy de 98 %\n",
    "# Pour rappel, une accuracy en dessous de 96 % est mauvaise !\n",
    "# → data.Tag.value_counts(normalize=True)\n",
    "accuracy_souhaitée = 0.98\n",
    "nb_lignes_à_erroring = int((1 - accuracy_souhaitée) * y_true.shape[0])\n",
    "y_pred = y_true_ohe.detach()\n",
    "y_pred[0:nb_lignes_à_erroring, :] = shift_tensor(y_pred[0:nb_lignes_à_erroring, :])\n",
    "print(\"Loss d'un modèle satisfaisant :\", loss_ce(y_pred, y_true))\n",
    "\n",
    "# Modèle qui prédit la classe modale : \n",
    "classe_modale = data.Tag.value_counts().nlargest(1).index[0]\n",
    "y_pred = np.full((len(data), num_tag), -3)\n",
    "y_pred[:, int(ordinal_enc_NER.transform([[classe_modale]]).item())] = 1\n",
    "y_pred = torch.tensor(y_pred, dtype=torch.float)\n",
    "print(\"Loss du modèle qui prédit argcount :\", loss_ce(y_pred, y_true))\n",
    "\n",
    "# Modèle aléatoire :\n",
    "y_pred = torch.tensor(\n",
    "    pd.get_dummies(torch.randint(0, num_tag, (len(data),))).astype(float).replace(0, -3).to_numpy(),\n",
    "    dtype=torch.float\n",
    ")\n",
    "print(\"Loss d'un modèle aléatoire :\", loss_ce(y_pred, y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc546603",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Paramétrage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fa288c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T20:58:50.497627Z",
     "start_time": "2022-07-26T20:58:50.234056Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55094ee2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T20:58:51.713334Z",
     "start_time": "2022-07-26T20:58:50.499273Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../models/camembert-base were not used when initializing CamembertForTokenClassification: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing CamembertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at ../models/camembert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = EntityModel(num_tag=num_tag)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a3056d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T20:58:51.735321Z",
     "start_time": "2022-07-26T20:58:51.714873Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11a4c074",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T20:58:51.757485Z",
     "start_time": "2022-07-26T20:58:51.736618Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimizer_parameters = [\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.001,\n",
    "    },\n",
    "    {\n",
    "        \n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41a22f0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T20:58:51.780358Z",
     "start_time": "2022-07-26T20:58:51.758805Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481 batchs vont être envoyés dans le réseau au cours de 2 epochs.\n"
     ]
    }
   ],
   "source": [
    "num_train_steps = int(len(sentences_minitrain) / PARAMS.MODEL.TRAIN_BATCH_SIZE * PARAMS.MODEL.EPOCHS)\n",
    "print(f\"{num_train_steps} batchs vont être envoyés dans le réseau au cours de {PARAMS.MODEL.EPOCHS} epochs.\")\n",
    "\n",
    "optimizer = torch.optim.AdamW(optimizer_parameters, lr=PARAMS.MODEL.LEARNING_RATE)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=num_train_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71702562",
   "metadata": {},
   "source": [
    "## Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56a0ff09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T20:58:53.682843Z",
     "start_time": "2022-07-26T20:58:51.781839Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed588728acf438ea41c79a30a9ba8ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-849a1cc380b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     train_loss = train_fn(minitrain_data_loader, model, optimizer,\n\u001b[0;32m----> 6\u001b[0;31m                           device, scheduler, pbar=pbar, num_epoch=num_epoch)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# On évalue le modèle à la fin de chaque epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dataml/LABTA/MRC_hbr/Pierre/PFPR/NER-code/ner_pytorch/engine.py\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(data_loader, model, optimizer, device, scheduler, pbar, num_epoch)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_batch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dataml/LABTA/MRC_hbr/Pierre/PFPR/NER-code/ner_pytorch/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, ids, mask, token_type_ids, target_tag)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;34m'labels'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtarget_tag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         }\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mbo_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbo_tag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_tag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1371\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m         )\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m         )\n\u001b[1;32m    835\u001b[0m         encoder_outputs = self.encoder(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m         return F.embedding(\n\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2041\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2043\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "best_loss = np.inf\n",
    "\n",
    "pbar = tqdm(range(PARAMS.MODEL.EPOCHS))\n",
    "for num_epoch, epoch in enumerate(pbar):\n",
    "    train_loss = train_fn(minitrain_data_loader, model, optimizer,\n",
    "                          device, scheduler, pbar=pbar, num_epoch=num_epoch)\n",
    "    \n",
    "    # On évalue le modèle à la fin de chaque epoch\n",
    "    valid_loss = eval_fn(valid_data_loader, model, device)\n",
    "    print(f\"Train Loss = {train_loss} Valid Loss = {valid_loss}\")\n",
    "    \n",
    "    if valid_loss < best_loss:\n",
    "        torch.save(\n",
    "            model.state_dict(), \n",
    "            PARAMS.PATHS_FR.MODEL_SAVED if PARAMS.LANGUAGE == 'fr' else PARAMS.PATHS_EN.MODEL_SAVED\n",
    "        )\n",
    "        best_loss = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f3ca33c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T21:05:37.548311Z",
     "start_time": "2022-07-26T21:05:37.444432Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-ce86e301d565>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         }\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mbert_fr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1371\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m         )\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m         )\n\u001b[1;32m    835\u001b[0m         encoder_outputs = self.encoder(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m         return F.embedding(\n\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2041\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2043\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "# temporaire\n",
    "from transformers import (BertForTokenClassification,\n",
    "                          CamembertConfig, CamembertForTokenClassification)\n",
    "\n",
    "# config = CamembertConfig.from_pretrained(\n",
    "#                 PARAMS.PATHS_FR.MODEL,\n",
    "#                 output_hidden_states=True\n",
    "#             )\n",
    "# bert_fr = CamembertForTokenClassification.from_pretrained(\n",
    "#     PARAMS.PATHS_FR.MODEL,\n",
    "#     num_labels=num_tag,\n",
    "#     local_files_only=True,\n",
    "#     return_dict=False\n",
    "# )\n",
    "\n",
    "kwargs = {\n",
    "            'input_ids': test_dataset[i]['ids'].unsqueeze(0),\n",
    "            'attention_mask': test_dataset[i]['mask'].unsqueeze(0),\n",
    "            'token_type_ids': test_dataset[i]['token_type_ids'].unsqueeze(0),\n",
    "            'labels': test_dataset[i]['target_tag'].unsqueeze(0),\n",
    "        }\n",
    "\n",
    "bert_fr(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cacf97",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Prédictions\n",
    "\n",
    "Utilisons le modèle finetuné pour prédire une nouvelle phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b07bac7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T18:28:12.876897Z",
     "start_time": "2022-07-26T18:28:04.437830Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0726 18:28:04.457361 140468396074816 modeling.py:577] loading archive file data/inputs/models/bert-base-uncased\n",
      "I0726 18:28:04.458981 140468396074816 modeling.py:598] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.6.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0726 18:28:06.540746 140468396074816 modeling.py:648] Weights of BertForTokenClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I0726 18:28:06.541644 140468396074816 modeling.py:651] Weights from pretrained model not used in BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On désérialise le meilleur modèle enregistré :\n",
    "model = EntityModel(num_tag=PARAMS.NUM_LABELS)\n",
    "model.load_state_dict(torch.load(f'data/models/model_trained_{PARAMS.LANGUAGE}.bin'))\n",
    "\n",
    "ordinal_enc_NER = joblib.load(f'data/outputs/ordinal_enc_NER_{PARAMS.LANGUAGE}.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e6be4d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Prédictions sur l'échantillon Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a4a1a06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T18:28:24.027875Z",
     "start_time": "2022-07-26T18:28:23.820779Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Thursday , Israeli troops killed a Palestinian gunman as he attempted to infiltrate the same settlement , in a botched attack that was claimed by the militant group , Hamas .\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() got an unexpected keyword argument 'return_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f95fc86fe51b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msingle_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Retrait des tokens qui ne contribuent pas à la loss (CLS, SEP, PAD) :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dataml/LABTA/MRC_hbr/Pierre/PFPR/NER-code/ner_pytorch/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, ids, mask, token_type_ids, target_tag)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         o1 = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids, \n\u001b[0;32m---> 52\u001b[0;31m                        return_dict=False)[0]\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mbo_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# tag = self.out_tag(bo_tag)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'return_dict'"
     ]
    }
   ],
   "source": [
    "i = 422 # 423\n",
    "single_example = test_dataset[i]\n",
    "print(' '.join(test_dataset.texts[i]))\n",
    "\n",
    "single_example = {k: single_example[k].unsqueeze(0) for k in single_example}\n",
    "with torch.no_grad():\n",
    "    _ = model.eval()\n",
    "    output, loss = model(**single_example)\n",
    "\n",
    "# Retrait des tokens qui ne contribuent pas à la loss (CLS, SEP, PAD) :\n",
    "output = output[single_example['mask'] == 1]\n",
    "\n",
    "predictions_probas = nn.functional.softmax(output, dim=1).detach().squeeze()\n",
    "predictions_probas, predictions_classes = torch.max(predictions_probas, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bdc51b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-02T15:06:57.979430Z",
     "start_time": "2022-07-02T15:06:57.949849Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lors', 'de', \"l'\", 'annonce', 'de', 'la', 'sélection', ',', 'le', ',', 'Thierry', 'Frémaux', ',', 'le', 'délégué', 'artistique', 'du', 'festival', ',', 'prévient', 'que', 'le', 'film', 'divisera', 'et', 'fera', 'polémique', '.', 'DIGITALDUNE', 'conçoit', 'et', 'développe', 'des', 'solutions', 'innovantes', 'pour', 'accompagner', 'ses', 'clients', 'dans', 'leurs', 'transformation', 'digitale', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ids': tensor([    5,  2100,     8,    17,    11,  1263,     8,    13,  1314,    21,\n",
       "             7,    16,    21,     7,  6724, 18401,   215,   483,    21,     7,\n",
       "            16,  8138,  2839,    25,  2602,    21,     7, 21953,    27,    16,\n",
       "           492, 21080,    55,    14,  1438,  8937,    21,     9,   160,  5807,\n",
       "         27944,   342, 21524, 19642,    14,  4611,    20,  1392, 12181,    24,\n",
       "          3139,    89,   783,    29,   187,  3508,  9436,    21,     9,     6,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'target_tag': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.getitem_enrichi(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e66dbdb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-02T15:07:01.174683Z",
     "start_time": "2022-07-02T15:07:01.103815Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>token_text</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>Lors</td>\n",
       "      <td>de</td>\n",
       "      <td>l</td>\n",
       "      <td>'</td>\n",
       "      <td>annonce</td>\n",
       "      <td>de</td>\n",
       "      <td>la</td>\n",
       "      <td>sélection</td>\n",
       "      <td></td>\n",
       "      <td>,</td>\n",
       "      <td>le</td>\n",
       "      <td></td>\n",
       "      <td>,</td>\n",
       "      <td>Thierry</td>\n",
       "      <td>Fré</td>\n",
       "      <td>m</td>\n",
       "      <td>aux</td>\n",
       "      <td></td>\n",
       "      <td>,</td>\n",
       "      <td>le</td>\n",
       "      <td>délégué</td>\n",
       "      <td>artistique</td>\n",
       "      <td>du</td>\n",
       "      <td>festival</td>\n",
       "      <td></td>\n",
       "      <td>,</td>\n",
       "      <td>prévient</td>\n",
       "      <td>que</td>\n",
       "      <td>le</td>\n",
       "      <td>film</td>\n",
       "      <td>diviser</td>\n",
       "      <td>a</td>\n",
       "      <td>et</td>\n",
       "      <td>fera</td>\n",
       "      <td>polémique</td>\n",
       "      <td></td>\n",
       "      <td>.</td>\n",
       "      <td>D</td>\n",
       "      <td>IG</td>\n",
       "      <td>ITAL</td>\n",
       "      <td>D</td>\n",
       "      <td>UNE</td>\n",
       "      <td>conçoit</td>\n",
       "      <td>et</td>\n",
       "      <td>développe</td>\n",
       "      <td>des</td>\n",
       "      <td>solutions</td>\n",
       "      <td>innovantes</td>\n",
       "      <td>pour</td>\n",
       "      <td>accompagner</td>\n",
       "      <td>ses</td>\n",
       "      <td>clients</td>\n",
       "      <td>dans</td>\n",
       "      <td>leurs</td>\n",
       "      <td>transformation</td>\n",
       "      <td>digitale</td>\n",
       "      <td></td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_id</th>\n",
       "      <td>5</td>\n",
       "      <td>2100</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>1263</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>1314</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>6724</td>\n",
       "      <td>18401</td>\n",
       "      <td>215</td>\n",
       "      <td>483</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>8138</td>\n",
       "      <td>2839</td>\n",
       "      <td>25</td>\n",
       "      <td>2602</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>21953</td>\n",
       "      <td>27</td>\n",
       "      <td>16</td>\n",
       "      <td>492</td>\n",
       "      <td>21080</td>\n",
       "      <td>55</td>\n",
       "      <td>14</td>\n",
       "      <td>1438</td>\n",
       "      <td>8937</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>160</td>\n",
       "      <td>5807</td>\n",
       "      <td>27944</td>\n",
       "      <td>342</td>\n",
       "      <td>21524</td>\n",
       "      <td>19642</td>\n",
       "      <td>14</td>\n",
       "      <td>4611</td>\n",
       "      <td>20</td>\n",
       "      <td>1392</td>\n",
       "      <td>12181</td>\n",
       "      <td>24</td>\n",
       "      <td>3139</td>\n",
       "      <td>89</td>\n",
       "      <td>783</td>\n",
       "      <td>29</td>\n",
       "      <td>187</td>\n",
       "      <td>3508</td>\n",
       "      <td>9436</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_code</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_label</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-org</td>\n",
       "      <td>B-org</td>\n",
       "      <td>B-org</td>\n",
       "      <td>B-org</td>\n",
       "      <td>B-org</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_true</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-org</td>\n",
       "      <td>B-org</td>\n",
       "      <td>B-org</td>\n",
       "      <td>B-org</td>\n",
       "      <td>B-org</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_proba</th>\n",
       "      <td>0.957896</td>\n",
       "      <td>0.959237</td>\n",
       "      <td>0.959236</td>\n",
       "      <td>0.959233</td>\n",
       "      <td>0.959064</td>\n",
       "      <td>0.959204</td>\n",
       "      <td>0.959209</td>\n",
       "      <td>0.959169</td>\n",
       "      <td>0.959034</td>\n",
       "      <td>0.959234</td>\n",
       "      <td>0.959221</td>\n",
       "      <td>0.959158</td>\n",
       "      <td>0.959183</td>\n",
       "      <td>0.959123</td>\n",
       "      <td>0.957761</td>\n",
       "      <td>0.958649</td>\n",
       "      <td>0.958631</td>\n",
       "      <td>0.958659</td>\n",
       "      <td>0.959166</td>\n",
       "      <td>0.959143</td>\n",
       "      <td>0.959175</td>\n",
       "      <td>0.95878</td>\n",
       "      <td>0.959145</td>\n",
       "      <td>0.958887</td>\n",
       "      <td>0.957493</td>\n",
       "      <td>0.959165</td>\n",
       "      <td>0.959087</td>\n",
       "      <td>0.958949</td>\n",
       "      <td>0.95904</td>\n",
       "      <td>0.958949</td>\n",
       "      <td>0.958346</td>\n",
       "      <td>0.958956</td>\n",
       "      <td>0.958998</td>\n",
       "      <td>0.959128</td>\n",
       "      <td>0.959113</td>\n",
       "      <td>0.959069</td>\n",
       "      <td>0.95904</td>\n",
       "      <td>0.958469</td>\n",
       "      <td>0.854208</td>\n",
       "      <td>0.853907</td>\n",
       "      <td>0.853777</td>\n",
       "      <td>0.853567</td>\n",
       "      <td>0.853089</td>\n",
       "      <td>0.959169</td>\n",
       "      <td>0.959331</td>\n",
       "      <td>0.959334</td>\n",
       "      <td>0.959318</td>\n",
       "      <td>0.959297</td>\n",
       "      <td>0.959303</td>\n",
       "      <td>0.959309</td>\n",
       "      <td>0.959288</td>\n",
       "      <td>0.959362</td>\n",
       "      <td>0.959334</td>\n",
       "      <td>0.959336</td>\n",
       "      <td>0.959351</td>\n",
       "      <td>0.959212</td>\n",
       "      <td>0.959092</td>\n",
       "      <td>0.959239</td>\n",
       "      <td>0.95908</td>\n",
       "      <td>0.953165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1         2         3         4         5   \\\n",
       "token_text        <s>      Lors        de         l         '   annonce   \n",
       "token_id            5      2100         8        17        11      1263   \n",
       "pred_code           0         0         0         0         0         0   \n",
       "pred_label          O         O         O         O         O         O   \n",
       "y_true              O         O         O         O         O         O   \n",
       "class_proba  0.957896  0.959237  0.959236  0.959233  0.959064  0.959204   \n",
       "\n",
       "                   6         7          8         9         10        11  \\\n",
       "token_text         de        la  sélection                   ,        le   \n",
       "token_id            8        13       1314        21         7        16   \n",
       "pred_code           0         0          0         0         0         0   \n",
       "pred_label          O         O          O         O         O         O   \n",
       "y_true              O         O          O         O         O         O   \n",
       "class_proba  0.959209  0.959169   0.959034  0.959234  0.959221  0.959158   \n",
       "\n",
       "                   12        13        14        15        16        17  \\\n",
       "token_text                    ,   Thierry       Fré         m       aux   \n",
       "token_id           21         7      6724     18401       215       483   \n",
       "pred_code           0         0         0         0         0         0   \n",
       "pred_label          O         O         O         O         O         O   \n",
       "y_true              O         O         O         O         O         O   \n",
       "class_proba  0.959183  0.959123  0.957761  0.958649  0.958631  0.958659   \n",
       "\n",
       "                   18        19        20       21          22        23  \\\n",
       "token_text                    ,        le  délégué  artistique        du   \n",
       "token_id           21         7        16     8138        2839        25   \n",
       "pred_code           0         0         0        0           0         0   \n",
       "pred_label          O         O         O        O           O         O   \n",
       "y_true              O         O         O        O           O         O   \n",
       "class_proba  0.959166  0.959143  0.959175  0.95878    0.959145  0.958887   \n",
       "\n",
       "                   24        25        26        27       28        29  \\\n",
       "token_text   festival                   ,  prévient      que        le   \n",
       "token_id         2602        21         7     21953       27        16   \n",
       "pred_code           0         0         0         0        0         0   \n",
       "pred_label          O         O         O         O        O         O   \n",
       "y_true              O         O         O         O        O         O   \n",
       "class_proba  0.957493  0.959165  0.959087  0.958949  0.95904  0.958949   \n",
       "\n",
       "                   30        31        32        33        34         35  \\\n",
       "token_text       film   diviser         a        et      fera  polémique   \n",
       "token_id          492     21080        55        14      1438       8937   \n",
       "pred_code           0         0         0         0         0          0   \n",
       "pred_label          O         O         O         O         O          O   \n",
       "y_true              O         O         O         O         O          O   \n",
       "class_proba  0.958346  0.958956  0.958998  0.959128  0.959113   0.959069   \n",
       "\n",
       "                  36        37        38        39        40        41  \\\n",
       "token_text                   .         D        IG      ITAL         D   \n",
       "token_id          21         9       160      5807     27944       342   \n",
       "pred_code          0         0         1         1         1         1   \n",
       "pred_label         O         O     B-org     B-org     B-org     B-org   \n",
       "y_true             O         O     B-org     B-org     B-org     B-org   \n",
       "class_proba  0.95904  0.958469  0.854208  0.853907  0.853777  0.853567   \n",
       "\n",
       "                   42        43        44         45        46         47  \\\n",
       "token_text        UNE   conçoit        et  développe       des  solutions   \n",
       "token_id        21524     19642        14       4611        20       1392   \n",
       "pred_code           1         0         0          0         0          0   \n",
       "pred_label      B-org         O         O          O         O          O   \n",
       "y_true          B-org         O         O          O         O          O   \n",
       "class_proba  0.853089  0.959169  0.959331   0.959334  0.959318   0.959297   \n",
       "\n",
       "                     48        49           50        51        52        53  \\\n",
       "token_text   innovantes      pour  accompagner       ses   clients      dans   \n",
       "token_id          12181        24         3139        89       783        29   \n",
       "pred_code             0         0            0         0         0         0   \n",
       "pred_label            O         O            O         O         O         O   \n",
       "y_true                O         O            O         O         O         O   \n",
       "class_proba    0.959303  0.959309     0.959288  0.959362  0.959334  0.959336   \n",
       "\n",
       "                   54              55        56        57       58        59  \n",
       "token_text      leurs  transformation  digitale                  .      </s>  \n",
       "token_id          187            3508      9436        21        9         6  \n",
       "pred_code           0               0         0         0        0         0  \n",
       "pred_label          O               O         O         O        O         O  \n",
       "y_true              O               O         O         O        O         O  \n",
       "class_proba  0.959351        0.959212  0.959092  0.959239  0.95908  0.953165  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_tokens = single_example['mask'].sum().item()\n",
    "ids = single_example['ids'].squeeze()[:nb_tokens]\n",
    "\n",
    "pd.DataFrame({\n",
    "    'token_text': [EntityDataset.tokenizer.decode([token]) for token in ids],\n",
    "    'token_id': ids,\n",
    "    'pred_code': predictions_classes,\n",
    "    'pred_label': ordinal_enc_NER.inverse_transform(predictions_classes.reshape(-1, 1)).squeeze(),\n",
    "    'y_true': ordinal_enc_NER.inverse_transform(single_example['target_tag'].squeeze()[:nb_tokens].reshape(-1, 1)).squeeze(),\n",
    "    'class_proba': predictions_probas\n",
    "}).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f48fe3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T16:25:07.435286Z",
     "start_time": "2022-06-06T16:25:07.407011Z"
    },
    "hidden": true
   },
   "source": [
    "On remarque que la base d'entraînement est parfois mal labélisée... cf exemples 415, ou 4222. Sur l'exemple `sentences_test[4222]`, on voit que le modèle arrive même à corriger une erreur de labélisation dans l'échantillon test !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed15775",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Prédictions sur notre propre texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20e02c11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T18:28:48.994476Z",
     "start_time": "2022-07-26T18:28:48.930191Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() got an unexpected keyword argument 'return_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c53a51124f38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m df = prédit_single_doc(doc, model=model, tokenizer=EntityDataset.tokenizer, \n\u001b[1;32m     29\u001b[0m                       \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPARAMS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAX_SENTENCE_LEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                       label_enc=ordinal_enc_NER)\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dataml/LABTA/MRC_hbr/Pierre/PFPR/NER-code/ner_pytorch/engine.py\u001b[0m in \u001b[0;36mprédit_single_doc\u001b[0;34m(doc, model, tokenizer, max_length, label_enc)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msingle_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m# Retrait des tokens qui ne contribuent pas à la loss (CLS, SEP, PAD) :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dataml/LABTA/MRC_hbr/Pierre/PFPR/NER-code/ner_pytorch/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, ids, mask, token_type_ids, target_tag)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         o1 = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids, \n\u001b[0;32m---> 52\u001b[0;31m                        return_dict=False)[0]\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mbo_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# tag = self.out_tag(bo_tag)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'return_dict'"
     ]
    }
   ],
   "source": [
    "# Succès\n",
    "doc = \"Le feu s'est déclaré en toute fin d'après-midi au sein de l'entreprise Génération piscine, spécialisée dans la fabrication de coques  polyester de piscines\"\n",
    "doc = \"Un important incendie brûle une dizaine d'hectares à Piolenc. Le feu est parti de la pizzeria dolce vita et a fait au moins 4 morts.\"\n",
    "doc = \"D'importants travaux sont menés par le grand paris express pendant tout l'été.\"\n",
    "doc = 'DIGITALDUNE fabrique des logiciels permettant la conception de maquettes en 3D.'\n",
    "doc = \"Synergie emballage est spécialisée dans le secteur d'activité du sciage et rabotage du bois. Selon les premiers éléments recueillis sur place, le feu serait parti dans l'une des trois travées de stockage de copeaux de bois.\"\n",
    "doc = \"Pour la quatrième fois en un mois, l'équipe du Service incendie de Matane est intervenue à l'usine GDS Valoribois de Matane pour une alerte incendie.\"\n",
    "doc = \"Les équipe de GDS tentent de trouver la source de ce problème récurrent, explique le responsable du service incendie.\"\n",
    "doc = \"Les locaux de l'entreprise CPMO, entreprise de machines-outils, ont totalement été détruits par les flammes dans la nuit de dimanche à lundi.\"\n",
    "doc = \"Coup de chaud pour l'entreprise Recaero. Basée dans le parc technologique Delta Sud à Verniolle, l'industrie aéronautique qui fait du traitement de surface et de l'usinage a eu une grosse frayeur ce mercredi 15 juin\"\n",
    "doc = \"L’incendie est parti du premier étage du bâtiment de l’entreprise TGS.\"\n",
    "doc = \"Un incendie s'est déclaré ce vendredi vers 13h30 à La-Tour-en-Maurienne (Savoie) à l'usine Poudres Hermillon, qui fabrique de la poudre d'aluminium.\"\n",
    "doc = \"Il était aux alentours de 21 heures samedi 18 juin 2022 quand une coupure totale d’électricité s’est produite dans l’usine Mat Friction, seul fabricant français de plaquettes de frein.\"\n",
    "doc = \"La cuve d'une chaudière à huile a pris feu dans un local de l’entreprise de Calaire Chimie.\"\n",
    "doc = \"Samedi 18 juin vers 15 h 30, les pompiers sont intervenus sur un feu qui s’était déclaré dans un bâtiment de stockage de l’entreprise Méricq, au sein de la zone d’activité Mestre-Marty à Estillac.\"\n",
    "doc = \"Dimanche 19 juin, aux alentours de 17 heures, un incendie s’est déclaré à l'entreprise Priméale, grossiste en fruits et légumes.\"\n",
    "\n",
    "\n",
    "# Fail mais de peu\n",
    "doc = \"Un incendie majeur touche l'usine de recyclage de Smurfit Kappa au Royaume-Uni.\"\n",
    "doc = 'Un incendie dans la nuit de lundi à mardi à Annecy dans un supermarché Carrefour, celui situé rue de Genève.' # + 'de', et ça passe\n",
    "doc = \"Ce lundi 13 juin, un important feu a ravagé le camping de l'Espiguette, situé au Grau-du-Roi, dans le Gard\"\n",
    "doc = \"L'entreprise Florentaise est spécialisée dans la fabrication de composts végétaux. Vers minuit, le feu est parti d'un tableau électrique.\" # Florentin, et ça passe\n",
    "doc = \"Un incendie s’est déclaré jeudi soir à l’usine de traitement de déchets de Vadec, à Colombier.\"\n",
    "doc = \"Lorsque le feu a pris dans le hall principal de la scierie Girard, rue Jean-Louis Guiot dans la zone industrielle de Neuve-Église (vallée de Villé).\"\n",
    "doc = \"Un transformateur électrique de 20 000 volts situé à proximité immédiate de l’entreprise Saunier-Duval, à Nantes, a pris feu vers 1 h du matin, dimanche 19 juin. Il n’y a pas eu de blessé.\"\n",
    "\n",
    "df = prédit_single_doc(doc, model=model, tokenizer=EntityDataset.tokenizer, \n",
    "                      max_length=PARAMS.MODEL.MAX_SENTENCE_LEN, \n",
    "                      label_enc=ordinal_enc_NER)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d8f028",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.11.1"
   }
  },
  "kernelspec": {
   "display_name": "parc_v1",
   "language": "python",
   "name": "parc_v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "notify_time": "10",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
