{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3757d46d",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "# 1 - NER PyTorch\n",
    "\n",
    "\n",
    "**Sources** :\n",
    "- Source de données Kaggle : https://www.kaggle.com/datasets/abhinavwalia95/entity-annotated-corpus\n",
    "- Tuto Abishek : https://www.youtube.com/watch?v=MqQ7rqRllIc\n",
    "\n",
    "**TODO**\n",
    "- [x] changer le padding par une autre valeur -> pas besoin en définitive.\n",
    "- [x] set num workers (minitrain, valid et test)\n",
    "- [x] peut-on monter la taille des batchs ?\n",
    "- [x] stratifier les splits\n",
    "- [x] enregistrer la running loss\n",
    "- [ ] est-on sûr que les special tokens ne contribuent pas à la loss ?\n",
    "- [ ] vérifier que le code <a href=\"https://www.kaggle.com/code/abhishek/entity-extraction-model-using-bert-pytorch\">ici</a> est le bon\n",
    "- [ ] gradual unfreezing\n",
    "- [ ] early stopping avec lightning\n",
    "- [ ] wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "857f0897",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T09:28:15.938531Z",
     "start_time": "2022-06-06T09:28:14.237849Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0606 09:28:15.558454 140644682426176 modeling.py:230] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import joblib\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "os.chdir('..')\n",
    "\n",
    "from ner_pytorch.config.params import PARAMS\n",
    "from ner_pytorch.dataset import EntityDataset\n",
    "from ner_pytorch.engine import eval_fn, train_fn\n",
    "from ner_pytorch.model import EntityModel\n",
    "from ner_pytorch.preprocessing import process_data\n",
    "from ner_pytorch.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c446f6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c5adc55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T09:28:16.613544Z",
     "start_time": "2022-06-06T09:28:15.940612Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>through</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>London</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word    Tag\n",
       "0  Sentence: 1      Thousands      O\n",
       "1  Sentence: 1             of      O\n",
       "2  Sentence: 1  demonstrators      O\n",
       "3  Sentence: 1           have      O\n",
       "4  Sentence: 1        marched      O\n",
       "5  Sentence: 1        through      O\n",
       "6  Sentence: 1         London  B-geo"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(PARAMS.PATHS.TRAIN, encoding='latin-1').drop('POS', axis=1)\n",
    "data[\"Sentence #\"] = data[\"Sentence #\"].fillna(method='ffill')\n",
    "data.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a2e002",
   "metadata": {
    "hidden": true
   },
   "source": [
    "En réalité, nous ne nous intéressons qu'à la prédiction des ORG, pour lesquelles 3 labels sont possibles :\n",
    "- B-org\n",
    "- I-org\n",
    "- O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd335958",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T09:28:16.783196Z",
     "start_time": "2022-06-06T09:28:16.614911Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O        0.964784\n",
       "B-org    0.019210\n",
       "I-org    0.016006\n",
       "Name: Tag, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Tag'] = data.Tag.mask(~data.Tag.isin(['B-org', 'I-org', 'O']), 'O')\n",
    "data.Tag.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05f9f966",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T09:28:16.881629Z",
     "start_time": "2022-06-06T09:28:16.785503Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag 3 categories : ['O' 'B-org' 'I-org']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1048575, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Sentence: 8</td>\n",
       "      <td>The</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Sentence: 8</td>\n",
       "      <td>International</td>\n",
       "      <td>B-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Sentence: 8</td>\n",
       "      <td>Atomic</td>\n",
       "      <td>I-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Sentence: 8</td>\n",
       "      <td>Energy</td>\n",
       "      <td>I-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Sentence: 8</td>\n",
       "      <td>Agency</td>\n",
       "      <td>I-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Sentence: 8</td>\n",
       "      <td>is</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Sentence: 8</td>\n",
       "      <td>to</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sentence #           Word    Tag\n",
       "153  Sentence: 8            The      O\n",
       "154  Sentence: 8  International  B-org\n",
       "155  Sentence: 8         Atomic  I-org\n",
       "156  Sentence: 8         Energy  I-org\n",
       "157  Sentence: 8         Agency  I-org\n",
       "158  Sentence: 8             is      O\n",
       "159  Sentence: 8             to      O"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tag = data.Tag.nunique()\n",
    "print(f'Tag {num_tag} categories :', data.Tag.unique(), end='\\n\\n')\n",
    "\n",
    "data.shape\n",
    "data[153:160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebe477c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T09:28:20.123848Z",
     "start_time": "2022-06-06T09:28:16.883850Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/outputs/label_enc_NER.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences, tag, label_enc_NER = process_data(data)\n",
    "joblib.dump(label_enc_NER, 'data/outputs/label_enc_NER.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ee00938",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T09:28:20.148028Z",
     "start_time": "2022-06-06T09:28:20.125232Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In', 'Beirut', ',', 'a', 'string', 'of', 'officials', 'voiced', 'their', 'anger', ',', 'while', 'at', 'the', 'United', 'Nations', 'summit', 'in', 'New', 'York', ',', 'Prime', 'Minister', 'Fouad', 'Siniora', 'said', 'the', 'Lebanese', 'people', 'are', 'resolute', 'in', 'preventing', 'such', 'attempts', 'from', 'destroying', 'their', 'spirit', '.']\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "['B-org' 'I-org' 'O']\n"
     ]
    }
   ],
   "source": [
    "# Démo : \n",
    "i = 10\n",
    "print(sentences[i], end='\\n')\n",
    "print(tag[i], end='\\n')\n",
    "print(label_enc_NER.classes_, end='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e124d7f5",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Split du jeu de données\n",
    "On split notre jeu de données de la façon suivante :\n",
    "- `test` = 20%\n",
    "- `train` = [`minitrain`, `valid`] = 80%\n",
    "- `minitrain` = 60%\n",
    "- `valid` = 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a371fd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T09:28:20.476151Z",
     "start_time": "2022-06-06T09:28:20.149593Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.964808\n",
       "0    0.019224\n",
       "1    0.015968\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2    0.965036\n",
       "0    0.018949\n",
       "1    0.016014\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(28777, 9591, 9591)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_test = int(PARAMS.SAMPLE_SIZES.TEST * len(sentences))\n",
    "len_valid = int(PARAMS.SAMPLE_SIZES.VALID * len(sentences))\n",
    "autre = label_enc_NER.transform(['O']).item()\n",
    "\n",
    "# En présence d'un jeu déséquilibré, il vaut mieux stratifier :\n",
    "strat_tag = [len([_ for _ in tag[i] if _ != autre]) > 0 for i in range(len(tag))]\n",
    "(\n",
    "    sentences_train, sentences_test,\n",
    "    tag_train, tag_test\n",
    ") = train_test_split(sentences, tag, random_state=PARAMS.SEED, \n",
    "                     test_size=len_test, stratify=strat_tag, shuffle=True)\n",
    "\n",
    "strat_tag_train = [len([_ for _ in tag_train[i] if _ != autre]) > 0 for i in range(len(tag_train))]\n",
    "(\n",
    "    sentences_minitrain, sentences_valid,\n",
    "    tag_minitrain, tag_valid\n",
    ") = train_test_split(sentences_train, tag_train, random_state=PARAMS.SEED, \n",
    "                     test_size=len_valid, stratify=strat_tag_train, shuffle=True)\n",
    "\n",
    "# Pour se rassurer sur la bonne représentativité de chaque classe dans les échantillons stratifiés : \n",
    "pd.Series(np.concatenate(tag_train)).value_counts(normalize=True)\n",
    "pd.Series(np.concatenate(tag_valid)).value_counts(normalize=True)\n",
    "\n",
    "len(sentences_minitrain), len(sentences_valid), len(sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1040cfa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T09:28:20.500696Z",
     "start_time": "2022-06-06T09:28:20.477603Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "minitrain_dataset = EntityDataset(\n",
    "    texts=sentences_minitrain, tags=tag_minitrain\n",
    ")\n",
    "minitrain_data_loader = DataLoader(\n",
    "    minitrain_dataset, batch_size=PARAMS.MODEL.TRAIN_BATCH_SIZE, num_workers=16 \n",
    ")\n",
    "\n",
    "valid_dataset = EntityDataset(\n",
    "    texts=sentences_valid, tags=tag_valid\n",
    ")\n",
    "valid_data_loader = DataLoader(\n",
    "    valid_dataset, batch_size=PARAMS.MODEL.VALID_BATCH_SIZE, num_workers=16\n",
    ")\n",
    "\n",
    "test_dataset = EntityDataset(\n",
    "    texts=sentences_test, tags=tag_test\n",
    ")\n",
    "test_data_loader = DataLoader(\n",
    "    test_dataset, batch_size=PARAMS.MODEL.VALID_BATCH_SIZE, num_workers=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb0fa33e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T09:28:20.530107Z",
     "start_time": "2022-06-06T09:28:20.502167Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Spanish', 'troops', 'will', 'join', 'the', 'European', 'Union', 'force', 'sent', 'to', 'protect', 'ships', 'against', 'hijackings', 'and', 'attacks', 'by', 'Somali', 'pirates', '.']\n",
      "ids: tensor([  101,  1996,  3009,  3629,  2097,  3693,  1996,  2647,  2586,  2486,\n",
      "         2741,  2000,  4047,  3719,  2114,  7632, 17364,  8613,  1998,  4491,\n",
      "         2011, 16831,  8350,  1012,   102,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0])\n",
      "mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "token_type_ids: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "target_tag: tensor([0, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "i = 40\n",
    "print(test_dataset.texts[i])\n",
    "for key, value in test_dataset[i].items():\n",
    "    print(key + ':', value)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "57e095f6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Expériences pré-entraînement\n",
    "\n",
    "Avant de lancer le modèle, quelle _loss_ serait considérée comme statisfaisante ? Calculons à l'avance les loss que donneraient :\n",
    "\n",
    "- un modèle qui prédit aléatoirement \n",
    "- un modèle qui prédit la classe modale (\"O\")\n",
    "- un modèle qui prédit de façon satisfaisante, avec une accuracy donnée*\n",
    "- un modèle oracle (prédiction parfaite)\n",
    "\n",
    "*Remarque : pour deux modèles qui produisent la même accuracy fixée, l'un peut être meilleur que l'autre ! En effet, les probas prédites peuvent être plus ou moins proches de la réalité, même si elles peuvent résulter en des prédictions binaires identiques (et donc en la même accuracy).\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ff8859a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T09:28:20.885401Z",
     "start_time": "2022-06-06T09:28:20.531571Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss_ce = nn.CrossEntropyLoss(reduction='mean')\n",
    "y_true = torch.tensor(label_enc_NER.transform(data.Tag), dtype=torch.long)\n",
    "\n",
    "y_true_ohe_parfait = torch.tensor(\n",
    "    pd.get_dummies(y_true).astype(float).replace(0, -1234).to_numpy(),\n",
    "    dtype=torch.float\n",
    ")\n",
    "\n",
    "# -3 est un nombre arbitraire qui affecte à la bonne classe une proba de 5%.\n",
    "y_true_ohe = torch.tensor(\n",
    "    pd.get_dummies(y_true).astype(float).replace(0, -3).to_numpy(),\n",
    "    dtype=torch.float\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a18b95fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T09:28:21.171369Z",
     "start_time": "2022-06-06T09:28:20.887047Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss oracle : tensor(0.)\n",
      "Loss d'un modèle satisfaisant : tensor(0.1160)\n",
      "Loss du modèle qui prédit argcount : tensor(0.1768)\n",
      "Loss d'un modèle aléatoire : tensor(2.7029)\n"
     ]
    }
   ],
   "source": [
    "#  Modèle oracle :\n",
    "y_pred = y_true_ohe_parfait.detach()\n",
    "print('Loss oracle :', loss_ce(y_pred, y_true))\n",
    "\n",
    "# Modèle avec une accuracy de 98 %\n",
    "# Pour rappel, une accuracy en dessous de 96 % est mauvaise !\n",
    "# → data.Tag.value_counts(normalize=True)\n",
    "accuracy_souhaitée = 0.98\n",
    "nb_lignes_à_erroring = int((1 - accuracy_souhaitée) * y_true.shape[0])\n",
    "y_pred = y_true_ohe.detach()\n",
    "y_pred[0:nb_lignes_à_erroring, :] = shift_tensor(y_pred[0:nb_lignes_à_erroring, :])\n",
    "print(\"Loss d'un modèle satisfaisant :\", loss_ce(y_pred, y_true))\n",
    "\n",
    "# Modèle qui prédit la classe modale : \n",
    "classe_modale = data.Tag.value_counts().nlargest(1).index[0]\n",
    "y_pred = np.full((len(data), num_tag), -3)\n",
    "y_pred[:, label_enc_NER.transform([classe_modale])[0]] = 1\n",
    "y_pred = torch.tensor(y_pred, dtype=torch.float)\n",
    "print(\"Loss du modèle qui prédit argcount :\", loss_ce(y_pred, y_true))\n",
    "\n",
    "# Modèle aléatoire :\n",
    "y_pred = torch.tensor(\n",
    "    pd.get_dummies(torch.randint(0, num_tag, (len(data),))).astype(float).replace(0, -3).to_numpy(),\n",
    "    dtype=torch.float\n",
    ")\n",
    "print(\"Loss d'un modèle aléatoire :\", loss_ce(y_pred, y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a44647",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Paramétrage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c825df95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T09:28:21.367625Z",
     "start_time": "2022-06-06T09:28:21.172801Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94bab65a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T09:28:23.460831Z",
     "start_time": "2022-06-06T09:28:21.369230Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0606 09:28:21.391445 140644682426176 modeling.py:577] loading archive file data/inputs/models/bert-base-uncased\n",
      "I0606 09:28:21.393192 140644682426176 modeling.py:598] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.6.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0606 09:28:23.454669 140644682426176 modeling.py:648] Weights of BertForTokenClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I0606 09:28:23.455593 140644682426176 modeling.py:651] Weights from pretrained model not used in BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    }
   ],
   "source": [
    "model = EntityModel(num_tag=num_tag)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df414600",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T09:28:23.484427Z",
     "start_time": "2022-06-06T09:28:23.462363Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bfa07d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T09:28:23.508862Z",
     "start_time": "2022-06-06T09:28:23.485953Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimizer_parameters = [\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.001,\n",
    "    },\n",
    "    {\n",
    "        \n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e60106a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T09:28:23.533274Z",
     "start_time": "2022-06-06T09:28:23.510384Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4496 batchs vont être envoyés dans le réseau au cours de 5 epochs.\n"
     ]
    }
   ],
   "source": [
    "num_train_steps = int(len(sentences_minitrain) / PARAMS.MODEL.TRAIN_BATCH_SIZE * PARAMS.MODEL.EPOCHS)\n",
    "print(f\"{num_train_steps} batchs vont être envoyés dans le réseau au cours de {PARAMS.MODEL.EPOCHS} epochs.\")\n",
    "\n",
    "optimizer = torch.optim.AdamW(optimizer_parameters, lr=PARAMS.MODEL.LEARNING_RATE)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=num_train_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053f91ba",
   "metadata": {},
   "source": [
    "## Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64d99b96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T12:06:12.833900Z",
     "start_time": "2022-06-06T09:28:23.534833Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db07d0d01154493db6fa36db07c400e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #0 : loss = 0.934720\n",
      "Batch #10 : loss = 0.374666\n",
      "Batch #20 : loss = 0.352794\n",
      "Batch #30 : loss = 0.260477\n",
      "Batch #40 : loss = 0.197657\n",
      "Batch #50 : loss = 0.184880\n",
      "Batch #60 : loss = 0.214349\n",
      "Batch #70 : loss = 0.215716\n",
      "Batch #80 : loss = 0.175364\n",
      "Batch #90 : loss = 0.186485\n",
      "Batch #100 : loss = 0.274800\n",
      "Batch #110 : loss = 0.204509\n",
      "Batch #120 : loss = 0.214829\n",
      "Batch #130 : loss = 0.187493\n",
      "Batch #140 : loss = 0.235032\n",
      "Batch #150 : loss = 0.243582\n",
      "Batch #160 : loss = 0.199930\n",
      "Batch #170 : loss = 0.175343\n",
      "Batch #180 : loss = 0.182348\n",
      "Batch #190 : loss = 0.173486\n",
      "Batch #200 : loss = 0.219236\n",
      "Batch #210 : loss = 0.198770\n",
      "Batch #220 : loss = 0.200684\n",
      "Batch #230 : loss = 0.203912\n",
      "Batch #240 : loss = 0.184976\n",
      "Batch #250 : loss = 0.197620\n",
      "Batch #260 : loss = 0.214885\n",
      "Batch #270 : loss = 0.225195\n",
      "Batch #280 : loss = 0.231820\n",
      "Batch #290 : loss = 0.173404\n",
      "Batch #300 : loss = 0.173494\n",
      "Batch #310 : loss = 0.200523\n",
      "Batch #320 : loss = 0.225873\n",
      "Batch #330 : loss = 0.195248\n",
      "Batch #340 : loss = 0.173643\n",
      "Batch #350 : loss = 0.174912\n",
      "Batch #360 : loss = 0.179210\n",
      "Batch #370 : loss = 0.228585\n",
      "Batch #380 : loss = 0.205207\n",
      "Batch #390 : loss = 0.214030\n",
      "Batch #400 : loss = 0.210422\n",
      "Batch #410 : loss = 0.222996\n",
      "Batch #420 : loss = 0.180211\n",
      "Batch #430 : loss = 0.170586\n",
      "Batch #440 : loss = 0.247452\n",
      "Batch #450 : loss = 0.199056\n",
      "Batch #460 : loss = 0.162053\n",
      "Batch #470 : loss = 0.193999\n",
      "Batch #480 : loss = 0.184531\n",
      "Batch #490 : loss = 0.178877\n",
      "Batch #500 : loss = 0.162141\n",
      "Batch #510 : loss = 0.189112\n",
      "Batch #520 : loss = 0.212051\n",
      "Batch #530 : loss = 0.171243\n",
      "Batch #540 : loss = 0.181111\n",
      "Batch #550 : loss = 0.195489\n",
      "Batch #560 : loss = 0.203425\n",
      "Batch #570 : loss = 0.212287\n",
      "Batch #580 : loss = 0.166700\n",
      "Batch #590 : loss = 0.176718\n",
      "Batch #600 : loss = 0.196357\n",
      "Batch #610 : loss = 0.176720\n",
      "Batch #620 : loss = 0.177569\n",
      "Batch #630 : loss = 0.221159\n",
      "Batch #640 : loss = 0.202933\n",
      "Batch #650 : loss = 0.180716\n",
      "Batch #660 : loss = 0.233243\n",
      "Batch #670 : loss = 0.220998\n",
      "Batch #680 : loss = 0.210422\n",
      "Batch #690 : loss = 0.183999\n",
      "Batch #700 : loss = 0.206041\n",
      "Batch #710 : loss = 0.165008\n",
      "Batch #720 : loss = 0.152561\n",
      "Batch #730 : loss = 0.165362\n",
      "Batch #740 : loss = 0.194991\n",
      "Batch #750 : loss = 0.167910\n",
      "Batch #760 : loss = 0.194253\n",
      "Batch #770 : loss = 0.171284\n",
      "Batch #780 : loss = 0.174088\n",
      "Batch #790 : loss = 0.188331\n",
      "Batch #800 : loss = 0.159256\n",
      "Batch #810 : loss = 0.211226\n",
      "Batch #820 : loss = 0.167971\n",
      "Batch #830 : loss = 0.206425\n",
      "Batch #840 : loss = 0.200490\n",
      "Batch #850 : loss = 0.142564\n",
      "Batch #860 : loss = 0.209511\n",
      "Batch #870 : loss = 0.166840\n",
      "Batch #880 : loss = 0.150806\n",
      "Batch #890 : loss = 0.200602\n",
      "Train Loss = 0.19952444279359446 Valid Loss = 0.06186874859035015\n",
      "Batch #0 : loss = 0.160575\n",
      "Batch #10 : loss = 0.198716\n",
      "Batch #20 : loss = 0.206230\n",
      "Batch #30 : loss = 0.162415\n",
      "Batch #40 : loss = 0.166582\n",
      "Batch #50 : loss = 0.148613\n",
      "Batch #60 : loss = 0.206146\n",
      "Batch #70 : loss = 0.167620\n",
      "Batch #80 : loss = 0.159539\n",
      "Batch #90 : loss = 0.130299\n",
      "Batch #100 : loss = 0.174086\n",
      "Batch #110 : loss = 0.151459\n",
      "Batch #120 : loss = 0.202589\n",
      "Batch #130 : loss = 0.135438\n",
      "Batch #140 : loss = 0.150033\n",
      "Batch #150 : loss = 0.214830\n",
      "Batch #160 : loss = 0.199071\n",
      "Batch #170 : loss = 0.159542\n",
      "Batch #180 : loss = 0.168203\n",
      "Batch #190 : loss = 0.169720\n",
      "Batch #200 : loss = 0.185601\n",
      "Batch #210 : loss = 0.134537\n",
      "Batch #220 : loss = 0.153165\n",
      "Batch #230 : loss = 0.178376\n",
      "Batch #240 : loss = 0.168965\n",
      "Batch #250 : loss = 0.206385\n",
      "Batch #260 : loss = 0.181396\n",
      "Batch #270 : loss = 0.182228\n",
      "Batch #280 : loss = 0.200546\n",
      "Batch #290 : loss = 0.154449\n",
      "Batch #300 : loss = 0.160350\n",
      "Batch #310 : loss = 0.173104\n",
      "Batch #320 : loss = 0.202235\n",
      "Batch #330 : loss = 0.144326\n",
      "Batch #340 : loss = 0.143312\n",
      "Batch #350 : loss = 0.164541\n",
      "Batch #360 : loss = 0.148175\n",
      "Batch #370 : loss = 0.194946\n",
      "Batch #380 : loss = 0.161930\n",
      "Batch #390 : loss = 0.183978\n",
      "Batch #400 : loss = 0.167183\n",
      "Batch #410 : loss = 0.183324\n",
      "Batch #420 : loss = 0.152744\n",
      "Batch #430 : loss = 0.142344\n",
      "Batch #440 : loss = 0.179481\n",
      "Batch #450 : loss = 0.197219\n",
      "Batch #460 : loss = 0.144891\n",
      "Batch #470 : loss = 0.159315\n",
      "Batch #480 : loss = 0.164429\n",
      "Batch #490 : loss = 0.178033\n",
      "Batch #500 : loss = 0.138205\n",
      "Batch #510 : loss = 0.168068\n",
      "Batch #520 : loss = 0.198317\n",
      "Batch #530 : loss = 0.157418\n",
      "Batch #540 : loss = 0.156385\n",
      "Batch #550 : loss = 0.175376\n",
      "Batch #560 : loss = 0.186439\n",
      "Batch #570 : loss = 0.164980\n",
      "Batch #580 : loss = 0.174987\n",
      "Batch #590 : loss = 0.186235\n",
      "Batch #600 : loss = 0.170766\n",
      "Batch #610 : loss = 0.177867\n",
      "Batch #620 : loss = 0.156831\n",
      "Batch #630 : loss = 0.156943\n",
      "Batch #640 : loss = 0.177754\n",
      "Batch #650 : loss = 0.188374\n",
      "Batch #660 : loss = 0.182974\n",
      "Batch #670 : loss = 0.158389\n",
      "Batch #680 : loss = 0.192594\n",
      "Batch #690 : loss = 0.170390\n",
      "Batch #700 : loss = 0.171919\n",
      "Batch #710 : loss = 0.181310\n",
      "Batch #720 : loss = 0.158709\n",
      "Batch #730 : loss = 0.158423\n",
      "Batch #740 : loss = 0.185402\n",
      "Batch #750 : loss = 0.146447\n",
      "Batch #760 : loss = 0.183587\n",
      "Batch #770 : loss = 0.139762\n",
      "Batch #780 : loss = 0.150739\n",
      "Batch #790 : loss = 0.161411\n",
      "Batch #800 : loss = 0.149505\n",
      "Batch #810 : loss = 0.183296\n",
      "Batch #820 : loss = 0.186325\n",
      "Batch #830 : loss = 0.194246\n",
      "Batch #840 : loss = 0.173715\n",
      "Batch #850 : loss = 0.140911\n",
      "Batch #860 : loss = 0.172873\n",
      "Batch #870 : loss = 0.162856\n",
      "Batch #880 : loss = 0.146778\n",
      "Batch #890 : loss = 0.167484\n",
      "Train Loss = 0.16748159375455646 Valid Loss = 0.063216032780086\n",
      "Batch #0 : loss = 0.170523\n",
      "Batch #10 : loss = 0.171677\n",
      "Batch #20 : loss = 0.156239\n",
      "Batch #30 : loss = 0.148335\n",
      "Batch #40 : loss = 0.163118\n",
      "Batch #50 : loss = 0.129809\n",
      "Batch #60 : loss = 0.185763\n",
      "Batch #70 : loss = 0.134050\n",
      "Batch #80 : loss = 0.138791\n",
      "Batch #90 : loss = 0.140268\n",
      "Batch #100 : loss = 0.156684\n",
      "Batch #110 : loss = 0.140696\n",
      "Batch #120 : loss = 0.200679\n",
      "Batch #130 : loss = 0.133260\n",
      "Batch #140 : loss = 0.166230\n",
      "Batch #150 : loss = 0.216896\n",
      "Batch #160 : loss = 0.142984\n",
      "Batch #170 : loss = 0.124022\n",
      "Batch #180 : loss = 0.170339\n",
      "Batch #190 : loss = 0.163213\n",
      "Batch #200 : loss = 0.168942\n",
      "Batch #210 : loss = 0.123602\n",
      "Batch #220 : loss = 0.148306\n",
      "Batch #230 : loss = 0.163786\n",
      "Batch #240 : loss = 0.160397\n",
      "Batch #250 : loss = 0.191751\n",
      "Batch #260 : loss = 0.187982\n",
      "Batch #270 : loss = 0.161751\n",
      "Batch #280 : loss = 0.172760\n",
      "Batch #290 : loss = 0.148051\n",
      "Batch #300 : loss = 0.158447\n",
      "Batch #310 : loss = 0.141747\n",
      "Batch #320 : loss = 0.176361\n",
      "Batch #330 : loss = 0.154575\n",
      "Batch #340 : loss = 0.148022\n",
      "Batch #350 : loss = 0.163157\n",
      "Batch #360 : loss = 0.156342\n",
      "Batch #370 : loss = 0.179240\n",
      "Batch #380 : loss = 0.163575\n",
      "Batch #390 : loss = 0.137544\n",
      "Batch #400 : loss = 0.159848\n",
      "Batch #410 : loss = 0.180834\n",
      "Batch #420 : loss = 0.136831\n",
      "Batch #430 : loss = 0.138966\n",
      "Batch #440 : loss = 0.175096\n",
      "Batch #450 : loss = 0.156512\n",
      "Batch #460 : loss = 0.147310\n",
      "Batch #470 : loss = 0.152275\n",
      "Batch #480 : loss = 0.134730\n",
      "Batch #490 : loss = 0.154853\n",
      "Batch #500 : loss = 0.149956\n",
      "Batch #510 : loss = 0.137906\n",
      "Batch #520 : loss = 0.166896\n",
      "Batch #530 : loss = 0.151877\n",
      "Batch #540 : loss = 0.138185\n",
      "Batch #550 : loss = 0.150428\n",
      "Batch #560 : loss = 0.132608\n",
      "Batch #570 : loss = 0.144519\n",
      "Batch #580 : loss = 0.142453\n",
      "Batch #590 : loss = 0.168361\n",
      "Batch #600 : loss = 0.161503\n",
      "Batch #610 : loss = 0.152601\n",
      "Batch #620 : loss = 0.153928\n",
      "Batch #630 : loss = 0.157275\n",
      "Batch #640 : loss = 0.154748\n",
      "Batch #650 : loss = 0.154949\n",
      "Batch #660 : loss = 0.131100\n",
      "Batch #670 : loss = 0.152130\n",
      "Batch #680 : loss = 0.163540\n",
      "Batch #690 : loss = 0.150162\n",
      "Batch #700 : loss = 0.161864\n",
      "Batch #710 : loss = 0.141392\n",
      "Batch #720 : loss = 0.140277\n",
      "Batch #730 : loss = 0.125637\n",
      "Batch #740 : loss = 0.142643\n",
      "Batch #750 : loss = 0.125077\n",
      "Batch #760 : loss = 0.146158\n",
      "Batch #770 : loss = 0.164913\n",
      "Batch #780 : loss = 0.135391\n",
      "Batch #790 : loss = 0.148434\n",
      "Batch #800 : loss = 0.138213\n",
      "Batch #810 : loss = 0.148069\n",
      "Batch #820 : loss = 0.140926\n",
      "Batch #830 : loss = 0.197712\n",
      "Batch #840 : loss = 0.147683\n",
      "Batch #850 : loss = 0.127782\n",
      "Batch #860 : loss = 0.191733\n",
      "Batch #870 : loss = 0.132901\n",
      "Batch #880 : loss = 0.134548\n",
      "Batch #890 : loss = 0.175862\n",
      "Train Loss = 0.15195958487689495 Valid Loss = 0.07456590091188749\n",
      "Batch #0 : loss = 0.161217\n",
      "Batch #10 : loss = 0.175273\n",
      "Batch #20 : loss = 0.148218\n",
      "Batch #30 : loss = 0.149547\n",
      "Batch #40 : loss = 0.141560\n",
      "Batch #50 : loss = 0.133295\n",
      "Batch #60 : loss = 0.154329\n",
      "Batch #70 : loss = 0.146493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #80 : loss = 0.146031\n",
      "Batch #90 : loss = 0.134234\n",
      "Batch #100 : loss = 0.153072\n",
      "Batch #110 : loss = 0.124656\n",
      "Batch #120 : loss = 0.163127\n",
      "Batch #130 : loss = 0.134035\n",
      "Batch #140 : loss = 0.129163\n",
      "Batch #150 : loss = 0.163015\n",
      "Batch #160 : loss = 0.152959\n",
      "Batch #170 : loss = 0.120873\n",
      "Batch #180 : loss = 0.137639\n",
      "Batch #190 : loss = 0.156223\n",
      "Batch #200 : loss = 0.143010\n",
      "Batch #210 : loss = 0.113951\n",
      "Batch #220 : loss = 0.139733\n",
      "Batch #230 : loss = 0.154226\n",
      "Batch #240 : loss = 0.147675\n",
      "Batch #250 : loss = 0.174658\n",
      "Batch #260 : loss = 0.150045\n",
      "Batch #270 : loss = 0.159185\n",
      "Batch #280 : loss = 0.176274\n",
      "Batch #290 : loss = 0.141631\n",
      "Batch #300 : loss = 0.154438\n",
      "Batch #310 : loss = 0.122628\n",
      "Batch #320 : loss = 0.157396\n",
      "Batch #330 : loss = 0.134598\n",
      "Batch #340 : loss = 0.122674\n",
      "Batch #350 : loss = 0.107843\n",
      "Batch #360 : loss = 0.142952\n",
      "Batch #370 : loss = 0.168944\n",
      "Batch #380 : loss = 0.137220\n",
      "Batch #390 : loss = 0.139399\n",
      "Batch #400 : loss = 0.136971\n",
      "Batch #410 : loss = 0.138847\n",
      "Batch #420 : loss = 0.146160\n",
      "Batch #430 : loss = 0.171034\n",
      "Batch #440 : loss = 0.150879\n",
      "Batch #450 : loss = 0.132546\n",
      "Batch #460 : loss = 0.150647\n",
      "Batch #470 : loss = 0.153800\n",
      "Batch #480 : loss = 0.147989\n",
      "Batch #490 : loss = 0.142449\n",
      "Batch #500 : loss = 0.119500\n",
      "Batch #510 : loss = 0.139220\n",
      "Batch #520 : loss = 0.144894\n",
      "Batch #530 : loss = 0.129332\n",
      "Batch #540 : loss = 0.131920\n",
      "Batch #550 : loss = 0.127136\n",
      "Batch #560 : loss = 0.128441\n",
      "Batch #570 : loss = 0.123197\n",
      "Batch #580 : loss = 0.139331\n",
      "Batch #590 : loss = 0.148353\n",
      "Batch #600 : loss = 0.159432\n",
      "Batch #610 : loss = 0.116784\n",
      "Batch #620 : loss = 0.144958\n",
      "Batch #630 : loss = 0.146998\n",
      "Batch #640 : loss = 0.147702\n",
      "Batch #650 : loss = 0.130962\n",
      "Batch #660 : loss = 0.156938\n",
      "Batch #670 : loss = 0.175369\n",
      "Batch #680 : loss = 0.148214\n",
      "Batch #690 : loss = 0.155166\n",
      "Batch #700 : loss = 0.181136\n",
      "Batch #710 : loss = 0.146713\n",
      "Batch #720 : loss = 0.135808\n",
      "Batch #730 : loss = 0.143682\n",
      "Batch #740 : loss = 0.137773\n",
      "Batch #750 : loss = 0.126738\n",
      "Batch #760 : loss = 0.173825\n",
      "Batch #770 : loss = 0.127922\n",
      "Batch #780 : loss = 0.134850\n",
      "Batch #790 : loss = 0.144420\n",
      "Batch #800 : loss = 0.127610\n",
      "Batch #810 : loss = 0.173730\n",
      "Batch #820 : loss = 0.134302\n",
      "Batch #830 : loss = 0.164319\n",
      "Batch #840 : loss = 0.172071\n",
      "Batch #850 : loss = 0.145190\n",
      "Batch #860 : loss = 0.163496\n",
      "Batch #870 : loss = 0.115715\n",
      "Batch #880 : loss = 0.129690\n",
      "Batch #890 : loss = 0.140733\n",
      "Train Loss = 0.1422141084074974 Valid Loss = 0.07983517354975143\n",
      "Batch #0 : loss = 0.148963\n",
      "Batch #10 : loss = 0.137532\n",
      "Batch #20 : loss = 0.142003\n",
      "Batch #30 : loss = 0.123388\n",
      "Batch #40 : loss = 0.128811\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f89fcf999737>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     train_loss = train_fn(minitrain_data_loader, model, optimizer,\n\u001b[0;32m----> 6\u001b[0;31m                           device, scheduler, pbar=pbar, num_epoch=num_epoch)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# On évalue le modèle à la fin de chaque epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dataml/LABTA/MRC_hbr/Pierre/PFPR/NER-code/ner_pytorch/engine.py\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(data_loader, model, optimizer, device, scheduler, pbar, num_epoch)\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Batch #{num_batch} : loss = {batch_loss:.6f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         torch.nn.utils.clip_grad_norm_(parameters=model.parameters(),\n\u001b[1;32m     29\u001b[0m                                        max_norm=PARAMS.MODEL.GRAD_MAX_NORM)\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_loss = np.inf\n",
    "\n",
    "pbar = tqdm(range(PARAMS.MODEL.EPOCHS))\n",
    "for num_epoch, epoch in enumerate(pbar):\n",
    "    train_loss = train_fn(minitrain_data_loader, model, optimizer,\n",
    "                          device, scheduler, pbar=pbar, num_epoch=num_epoch)\n",
    "    \n",
    "    # On évalue le modèle à la fin de chaque epoch\n",
    "    test_loss = eval_fn(valid_data_loader, model, device)\n",
    "    print(f\"Train Loss = {train_loss} Valid Loss = {test_loss}\")\n",
    "    \n",
    "    if test_loss < best_loss:\n",
    "        torch.save(model.state_dict(), PARAMS.PATHS.MODEL_SAVED)\n",
    "        best_loss = test_loss"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2500efd6",
   "metadata": {},
   "source": [
    "Train Loss = 0.2257268762588501 Valid Loss = 0.07416860982775689\n",
    "Train Loss = 0.18738604148228963 Valid Loss = 0.06755437478423118\n",
    "Train Loss = 0.1802095964219835 Valid Loss = 0.06718131552139918\n",
    "Train Loss = 0.17476963301499684 Valid Loss = 0.06649512027700742\n",
    "Train Loss = 0.17063462575276692 Valid Loss = 0.06719479302565257"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ab9aa5",
   "metadata": {},
   "source": [
    "## Prédictions\n",
    "\n",
    "Utilisons le modèle finetuné pour prédire une nouvelle phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bae5c35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T12:06:29.908318Z",
     "start_time": "2022-06-06T12:06:27.798840Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0606 12:06:27.818886 140644682426176 modeling.py:577] loading archive file data/inputs/models/bert-base-uncased\n",
      "I0606 12:06:27.820515 140644682426176 modeling.py:598] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.6.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0606 12:06:29.735961 140644682426176 modeling.py:648] Weights of BertForTokenClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I0606 12:06:29.736854 140644682426176 modeling.py:651] Weights from pretrained model not used in BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On désérialise le meilleur modèle enregistré :\n",
    "model = EntityModel(num_tag=num_tag)\n",
    "model.load_state_dict(torch.load('data/models/model_trained.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efa71572",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T12:06:40.333462Z",
     "start_time": "2022-06-06T12:06:40.252497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automobile sales in the United States fell in June as high gasoline prices kept consumers away from trucks and sports utility vehicles that require a lot of fuel .\n"
     ]
    }
   ],
   "source": [
    "i = 2\n",
    "single_example = test_dataset[i]\n",
    "print(' '.join(test_dataset.texts[i]))\n",
    "nb_tokens = single_example['mask'].sum().item()\n",
    "\n",
    "single_example = {k: single_example[k].unsqueeze(0) for k in single_example}\n",
    "with torch.no_grad():\n",
    "    output, loss = model(**single_example)\n",
    "predictions_probas = nn.functional.softmax(output, dim=2).detach().squeeze()\n",
    "predictions_probas, predictions_classes = torch.max(predictions_probas, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cdf4667",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T12:06:44.479598Z",
     "start_time": "2022-06-06T12:06:44.430911Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>token_text</th>\n",
       "      <td>[CLS]</td>\n",
       "      <td>automobile</td>\n",
       "      <td>sales</td>\n",
       "      <td>in</td>\n",
       "      <td>the</td>\n",
       "      <td>united</td>\n",
       "      <td>states</td>\n",
       "      <td>fell</td>\n",
       "      <td>in</td>\n",
       "      <td>june</td>\n",
       "      <td>as</td>\n",
       "      <td>high</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>prices</td>\n",
       "      <td>kept</td>\n",
       "      <td>consumers</td>\n",
       "      <td>away</td>\n",
       "      <td>from</td>\n",
       "      <td>trucks</td>\n",
       "      <td>and</td>\n",
       "      <td>sports</td>\n",
       "      <td>utility</td>\n",
       "      <td>vehicles</td>\n",
       "      <td>that</td>\n",
       "      <td>require</td>\n",
       "      <td>a</td>\n",
       "      <td>lot</td>\n",
       "      <td>of</td>\n",
       "      <td>fuel</td>\n",
       "      <td>.</td>\n",
       "      <td>[SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_id</th>\n",
       "      <td>101</td>\n",
       "      <td>9935</td>\n",
       "      <td>4341</td>\n",
       "      <td>1999</td>\n",
       "      <td>1996</td>\n",
       "      <td>2142</td>\n",
       "      <td>2163</td>\n",
       "      <td>3062</td>\n",
       "      <td>1999</td>\n",
       "      <td>2238</td>\n",
       "      <td>2004</td>\n",
       "      <td>2152</td>\n",
       "      <td>13753</td>\n",
       "      <td>7597</td>\n",
       "      <td>2921</td>\n",
       "      <td>10390</td>\n",
       "      <td>2185</td>\n",
       "      <td>2013</td>\n",
       "      <td>9322</td>\n",
       "      <td>1998</td>\n",
       "      <td>2998</td>\n",
       "      <td>9710</td>\n",
       "      <td>4683</td>\n",
       "      <td>2008</td>\n",
       "      <td>5478</td>\n",
       "      <td>1037</td>\n",
       "      <td>2843</td>\n",
       "      <td>1997</td>\n",
       "      <td>4762</td>\n",
       "      <td>1012</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_code</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_label</th>\n",
       "      <td>B-org</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-org</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>I-org</td>\n",
       "      <td>O</td>\n",
       "      <td>I-org</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-org</td>\n",
       "      <td>B-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_proba</th>\n",
       "      <td>0.999283</td>\n",
       "      <td>0.990896</td>\n",
       "      <td>0.999125</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.998966</td>\n",
       "      <td>0.980616</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.998936</td>\n",
       "      <td>0.999536</td>\n",
       "      <td>0.499692</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.499783</td>\n",
       "      <td>0.998798</td>\n",
       "      <td>0.999391</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999527</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999503</td>\n",
       "      <td>0.999373</td>\n",
       "      <td>0.998251</td>\n",
       "      <td>0.99998</td>\n",
       "      <td>0.998454</td>\n",
       "      <td>0.999294</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.998281</td>\n",
       "      <td>0.999675</td>\n",
       "      <td>0.998903</td>\n",
       "      <td>0.999703</td>\n",
       "      <td>0.499861</td>\n",
       "      <td>0.999317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0           1         2         3         4         5   \\\n",
       "token_text      [CLS]  automobile     sales        in       the    united   \n",
       "token_id          101        9935      4341      1999      1996      2142   \n",
       "class_code          0           2         2         2         2         2   \n",
       "class_label     B-org           O         O         O         O         O   \n",
       "class_proba  0.999283    0.990896  0.999125  0.999999  0.998966  0.980616   \n",
       "\n",
       "                   6         7         8         9         10        11  \\\n",
       "token_text     states      fell        in      june        as      high   \n",
       "token_id         2163      3062      1999      2238      2004      2152   \n",
       "class_code          0         2         2         1         2         1   \n",
       "class_label     B-org         O         O     I-org         O     I-org   \n",
       "class_proba  0.333333  0.998936  0.999536  0.499692  0.999999  0.499783   \n",
       "\n",
       "                   12        13    14         15    16        17        18  \\\n",
       "token_text   gasoline    prices  kept  consumers  away      from    trucks   \n",
       "token_id        13753      7597  2921      10390  2185      2013      9322   \n",
       "class_code          2         2     2          2     2         2         2   \n",
       "class_label         O         O     O          O     O         O         O   \n",
       "class_proba  0.998798  0.999391     1   0.999527     1  0.999503  0.999373   \n",
       "\n",
       "                   19       20        21        22        23        24  \\\n",
       "token_text        and   sports   utility  vehicles      that   require   \n",
       "token_id         1998     2998      9710      4683      2008      5478   \n",
       "class_code          2        2         2         2         2         2   \n",
       "class_label         O        O         O         O         O         O   \n",
       "class_proba  0.998251  0.99998  0.998454  0.999294  0.999999  0.999999   \n",
       "\n",
       "                   25        26        27        28        29        30  \n",
       "token_text          a       lot        of      fuel         .     [SEP]  \n",
       "token_id         1037      2843      1997      4762      1012       102  \n",
       "class_code          2         2         2         2         0         0  \n",
       "class_label         O         O         O         O     B-org     B-org  \n",
       "class_proba  0.998281  0.999675  0.998903  0.999703  0.499861  0.999317  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = single_example['ids'].squeeze()[:nb_tokens]\n",
    "pd.DataFrame({\n",
    "    'token_text': [EntityDataset.tokenizer.decode([token]) for token in ids],\n",
    "    'token_id': ids,\n",
    "    'class_code': predictions_classes[:nb_tokens],\n",
    "    'class_label': label_enc_NER.inverse_transform(predictions_classes)[:nb_tokens],\n",
    "    'class_proba': predictions_probas[:nb_tokens]\n",
    "}).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3e5d09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-05T12:49:29.041132Z",
     "start_time": "2022-06-05T12:49:29.011978Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.11.1"
   }
  },
  "kernelspec": {
   "display_name": "parc_v1",
   "language": "python",
   "name": "parc_v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "notify_time": "10",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
